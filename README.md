# üöÄ ADF & Databricks Migration Project

This repository showcases two practical migration workflows:
1. Azure Data Factory (ADF) to Synapse Analytics Pipelines
2. Databricks Notebooks to Microsoft Fabric Workspace

Each project demonstrates how to adapt cloud-native tools across platforms while preserving pipeline functionality and notebook logic.

---

## ‚úÖ Method 1: ADF to Synapse via Scripted Migration

### Objective
To migrate pipelines, datasets, and linked services from ADF to Synapse using PowerShell and exported JSON definitions.

### Steps
- Export support files from ADF (Download support .zip).
- Upload and extract in Azure Cloud Shell.
- Use `Set-AzSynapsePipeline`, `Set-AzSynapseDataset`, and `Set-AzSynapseLinkedService` commands.
- Validate and run the Synapse pipeline.

---

## ‚úÖ Method 2: ADF to Synapse via JSON Copy

### Objective
To replicate ADF pipeline logic in Synapse Studio manually using JSON code.

### Steps
- Open the ADF pipeline JSON in code view.
- Copy and paste into a new Synapse pipeline.
- Manually create required linked services and datasets.
- Validate and test.

---

## ‚úÖ Databricks to Fabric Notebook Migration

### Objective
To migrate Spark-based transformation logic and mount-based data access from Databricks notebooks to Fabric notebooks.

### Key Adjustments:
| Feature                  | Databricks                          | Microsoft Fabric                     |
|--------------------------|-------------------------------------|--------------------------------------|
| Mount Points             | `/mnt/ctnadls/...`                  | `Files/...` (Lakehouse path)         |
| Secrets Access           | `dbutils.secrets.get(...)`          | `notebookutils.credentials.getSecret(...)` |
| Table Reads              | `.load("/mnt/...")`                 | `.read.table("tablename")`           |
| File Write               | `.write.csv("/mnt/...")`            | `.write.csv("Files/...")`            |

### Notebooks:
1. Read CSV from ADLS
2. Clean & Transform data, write to ADLS
3. Utility functions for reading
4. Final notebook using modular functions

---

## üß† Few Important Points:

- Mount-based logic in Databricks does not work in Fabric.
- Synapse and ADF share a common JSON schema for pipelines and datasets.
- Fabric notebooks require a different way to access secrets and file paths.

---

## üìå Prerequisites

- Azure Subscription with:
  - Azure Data Factory
  - Synapse Analytics Workspace
  - Databricks Workspace
  - Microsoft Fabric enabled
  - Azure Key Vault (for secret management)
  - Azure Data Lake Gen2 Storage

---

## üèÅ Conclusion

This repo demonstrates a hands-on guide for cross-platform cloud migrations of both pipelines and notebooks. It helps you understand compatibility differences and adapt solutions for a unified cloud data environment.
